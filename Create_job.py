import os

# Include the Lambda layer extracted location

import boto3
import time
import datetime
import json

region = 'eu-west-1'

data_set_id = '33f6292430649291ad0fa71ad7f37cae'
bucket_name = 'adx-text-gary-jul-21'
object_key = 'clamscan.log'

path = os.environ['MALWARE_PATH']


def recurse_files(path):
    for dirpath, dirs, files in os.walk(path):
        for file in files:
            s3.bucket(bucket_name).upload_file(os.path.join(dirpath, file), file)
            create_job(data_set_id, bucket_name, region)



def create_job(data_set_id, bucket_name, region):
    # Setup the boto3 clients needed
    dataexchange = boto3.client(
        service_name='dataexchange',
        region_name=region

    )
 #   marketplace_catalog = boto3.client(
  #      service_name='marketplace-catalog',
   #     region_name=region
    #)


    # CREATE REVISION under the dataset provided as an environment variable
    current_time_for_creating_revision = datetime.datetime.utcnow().strftime("%d %B %Y %I:%M%p UTC")
    create_revision_response = dataexchange.create_revision(DataSetId=data_set_id,
                                                     Comment='Revision created programmatically on ' + current_time_for_creating_revision)
    revision_id = create_revision_response['Id']

    # CREATE JOB under the revision to import file from S3 to DataExchange
    create_job_s3_import = dataexchange.create_job(
        Type='IMPORT_ASSETS_FROM_S3',
        Details={
            'ImportAssetsFromS3': {
                'DataSetId': data_set_id,
                'RevisionId': revision_id,
                'AssetSources': [
                    {
                        'Bucket': bucket_name,
                        'Key': object_key
                    }

                ]
            }
        }
    )

    # Filter the ID of the Job from the response
    job_id = create_job_s3_import['Id']

    # invoke START JOB on the created job to change it from Waiting to
    # Completed state
    start_created_job = dataexchange.start_job(JobId=job_id)

    # GET JOB details to track the state of the job and wait until it reaches
    # COMPLETED state
    job_status = ''

    while job_status != 'COMPLETED':
        get_job_status = dataexchange.get_job(JobId=job_id)
        job_status = get_job_status['State']
        print('Job Status ' + job_status)
        
        if job_status =='ERROR':
            job_errors = get_job_status['Errors']
            print('JobId: {} failed with error:{}'.format(job_id, job_errors))
            exit()
        
        time.sleep(3)
        
    # Finalize revision by invoking UPDATE REVISION
    current_time_for_finalize_revision = datetime.datetime.utcnow().strftime("%d %B %Y %I:%M%p UTC")
    print(current_time_for_finalize_revision)
    finalize_revision = dataexchange.update_revision(DataSetId=data_set_id, 
                                                    RevisionId=revision_id, 
                                                    Finalized=True,
                                                    Comment='Revision finalized programmatically on ' + current_time_for_finalize_revision)

    
    return ('Your data has been imported successfully')

if __name__ == '__main__':
    recurse_files(path)
